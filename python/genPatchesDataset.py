#!/usr/bin/env python
# @Date:   2020-08-08T17:06:36+02:00
# @Email:  ibrejcha@fit.vutbr.cz; brejchaja@gmail.com
# @Project: LandscapeAR
# @Last modified time: 2020-08-11T17:51:42+02:00
# @License: Copyright 2020 Brno University of Technology,
# Faculty of Information Technology,
# Božetěchova 2, 612 00, Brno, Czech Republic
#
# Redistribution and use in source code form, with or without modification,
# are permitted provided that the following conditions are met:
#
# 1. Redistributions must retain the above copyright notice, this list of
#    conditions and the following disclaimer.
#
# 2. Neither the name of the copyright holder nor the names of its contributors
#    may be used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# 3. Redistributions must be pursued only for non-commercial research
#    collaboration and demonstration purposes.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF  FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


from __future__ import print_function

import argparse as ap
import numpy as np
from scipy import misc
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
#plt.ion()
import os.path
import imageio
from skimage.transform import resize
from skimage import img_as_ubyte
import glob
import re
import shutil
import random
import math
import pymap3d as pm3d
import gzip
from scipy.ndimage import zoom
import torch
from multiprocessing.pool import Pool
from multiprocessing import get_context, Semaphore
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

from pose_estimation.patchSamplingDepth import getPatches, loadDepth
from training.MultimodalPatchesDataset import MultimodalPatchesDataset

def buildArgumentParser():
    parser = ap.ArgumentParser()
    parser.add_argument("input_dir", help = """Input directory containing
    rendered images as generated by itr --render_photoviews.""")
    parser.add_argument("fov_type", help = """Field-of-view options: fixed,
    real. Fixed generates dataset with fixed 60 degrees Field-of-View (FOV),
    real uses FOV of the original photo""")
    parser.add_argument("domain", help = """Whether to generate single domain,
    or cross-domain dataset, options: synth-synth, real-synth, real-real""")
    parser.add_argument("output_dir", help = """Directory where to store the
    created dataset.""")
    parser.add_argument("-n", "--number_shared", help = """Threshold defining
    how many 3D points shared between two views are needed to include the
    pair of views into the dataset. Default 10.""", type = int, default = "10")
    parser.add_argument("-m", "--max_pairs", default = 1000, help = """Number of
    pairs in one dataset tfrecords file. Default 1000.""", type = int)
    parser.add_argument("-a", "--above_ground", type = int, default = 1, help = """
    whether include only views above ground (=1), or not (0). Default: include
    only views above ground, 1""")
    parser.add_argument("-p", "--plot_orientations",
    help="Whether to plot statistics about pair orientations.",
    action="store_true")
    parser.add_argument("--img_list", help="""File containing list of image
    names which will be used as the first view. Use to restrict the set
    which will be generated, so that several processes may work in parallel.""")
    return parser

workers_semaphore = Semaphore(16)

class PatchesDatasetCreator(object):

    def __init__(self, args):
        self.args = args
        self.resetPairVars()
        self.loaded_images = {}
        self.loaded_depths = {}
        self.num_workers = 1

    def resetPairVars(self):
        self.pair_rot_mags = []
        self.pair_positions = []
        self.pair_orientations = []
        self.pair_names = []

    def parseTracks(self, filename):
        """
        returns - sorted_keys list of keys sorted according to the number of shared
        3D points (the txt file is already sorted as generated by
        itr)
                - dictionary indexed by image name containing the number of shared
                3D points.
        """

        tracks = {}
        sorted_keys = []
        with open(filename, 'r') as f:
            for line in f.readlines():
                parts = line.split(" ")
                view_id = parts[0]
                name = parts[1]
                num_shared = parts[2]
                tracks[name] = int(num_shared)
                sorted_keys.append(name)
        return sorted_keys, tracks

    def loadAndResizeDepth(self, image_filename, image_width, orig_width = 2048, orig_height = 2048):
        """ orig_width and orig_height are dimensions of the depth matrix.
            They need to be read from the corresponding rendered image.
        """
        img_key = image_filename + "_" + str(image_width)
        if (img_key in self.loaded_depths):
            return self.loaded_depths[img_key]

        with gzip.open(image_filename, 'rb') as f:
            depth_txt = f.read()
            depth = np.fromstring(depth_txt, dtype=float, sep=' ').reshape(orig_width, orig_height)
            ratio_w = image_width / float(orig_width)
            ratio_h = image_width / float(orig_height)
            depth = zoom(depth, (ratio_w, ratio_h))
            self.loaded_depths[img_key] = depth
            return depth

    def getImageSize(self, image_filename):
        """ returns width and height of the image
        """
        m = imageio.imread(image_filename)
        return m.shape[1], m.shape[0]

    def loadAndResizeImage(self, image_filename, image_width):
        img_key = image_filename + "_" + str(image_width)
        if (img_key in self.loaded_images):
            return self.loaded_images[img_key]

        m = imageio.imread(image_filename)
        m = img_as_ubyte(resize(m, (image_width, image_width), anti_aliasing=True))
        self.loaded_images[img_key] = m
        return m


    def get_matrix(self, filename):
        with open(filename, "r") as f:
            lines = f.readlines()
            mat = []
            line_arr = []
            for line in lines:
              for mat_line in line.strip().split("\n"):
                  for x in mat_line.split(" "):
                      try:
                          num = float(x)
                          line_arr.append(num)
                          if (len(line_arr) == 4):
                              mat.append(line_arr)
                              line_arr = []
                      except:
                          pass
            return np.array(mat)



    def writeDebugFile(self, str):
        with open(os.path.join(self.args.output_dir, "debug.txt"), "a") as job:
            job.write(str + "\n")

    def writeJobFile(self, first, second, batch):
        batch_str = "%06d" % batch
        with open(os.path.join(self.args.output_dir, "job.txt"), "a") as job:
            job.write(batch_str + "," + first + ":" + second + "\n")

    def isAboveGround(self, image_base):
        if (self.args.above_ground == 0):
            return 1 #is always above ground since we need to allow all images
        #else we need to verify
        props_file = os.path.join(self.args.input_dir, image_base + "_properties.txt")
        if (not os.path.isfile(props_file)):
            print("Could not find properties of a file: " + image_base + ", assuming it is above ground.")
            return 1

        above = 0
        with open(props_file, "r") as props:
            lines = props.readlines()
            for line in lines:
                parts = line.split()
                if (parts[0] == "isAboveGround"):
                    above = int(parts[1])
        return above

    def getRotScale(self, M):
        """Assuming M is 3x3 matrix"""
        sx = np.linalg.norm(M[:3, 0])
        sy = np.linalg.norm(M[:3, 1])
        sz = np.linalg.norm(M[:3, 2])
        scale = np.array([sx, sy, sz])
        scale_M = np.tile(scale, [3, 1])
        R = M/scale_M
        return R, scale

    # FIXME TODO: implement loading of scene_origin from dataset file
    def ecef2enu(self, M, origin, scene_origin = np.array([4.40145e+06, 597011, 4.56599e+06])):
        """M is a row-wise atrix of 3D ecef points
           origin is a vector in ecef defining the origin for ENU
           scene_origin will be added to both origin and each point in M before
           the transformation
        """
        ell = pm3d.EarthEllipsoid(model='wgs84')
        lat, lon, alt = pm3d.ecef2geodetic(origin[0] + scene_origin[0], origin[1] + scene_origin[1], origin[2] + scene_origin[2], ell)
        res = []
        for i in range(M.shape[0]):
            e,n,u = pm3d.ecef2enu(M[i,0] + scene_origin[0], M[i,1] + scene_origin[1], M[i,2] + scene_origin[2], lat, lon, alt, ell)
            res.append(np.array([e,n,u]))
        return np.array(res)

    def Rx(self, theta):
        return np.array([[1,0,0],[0, np.cos(theta), np.sin(theta)], [0, -np.sin(theta), np.cos(theta)]])
    def Ry(self, theta):
        return np.array([[np.cos(theta),0,-np.sin(theta)],[0,1,0], [np.sin(theta), 0, np.cos(theta)]])
    def Rz(self, theta):
        return np.array([[np.cos(theta), np.sin(theta), 0],[-np.sin(theta),np.cos(theta),0], [0,0,1]])

    def ecef2EnuMat(self, origin, scene_origin = np.array([4.40145e+06, 597011, 4.56599e+06])):
        ell = pm3d.EarthEllipsoid(model='wgs84')
        phi, lam, alt = pm3d.ecef2geodetic(origin[0] + scene_origin[0], origin[1] + scene_origin[1], origin[2] + scene_origin[2], ell)
        """ phi is latitude, lam is longitude
            transformation taken from:
            https://gssc.esa.int/navipedia/index.php/Transformations_between_ECEF_and_ENU_coordinates
        """
        pi_2 = np.pi / 2.0
        rx = self.Rx(pi_2 - phi)
        rz = self.Rz(pi_2 + lam)
        return rx.dot(rz)

    def readListBasenames(self, filename):
        """Reads the list from file"""
        with open(filename, 'r') as f:
            lines = [line.strip().split(".")[0] for line in f]
            return lines


    def writeList(self, l, outfile):
        with open(outfile, 'w') as f:
            for i in l:
                f.write("%s\n" % i)


    def plotPositionsOrientations(self, mv_1, im_1, image_base):
        if (not self.args.plot_orientations):
            return
        dpi=96
        plt.figure(figsize=(1800/dpi, 600/dpi), dpi=dpi)
        plt.subplot(131)
        plt.imshow(im_1)
        plt.title(image_base)
        plt.subplot(132)
        plt.hist(np.array(self.pair_rot_mags))
        plt.title("Histogram of ||R_2 R_1^T||")
        ax = plt.subplot(133, projection='3d')
        pp = np.array(self.pair_positions)
        po = np.array(self.pair_orientations)
        first_cam_RT = mv_1.reshape(4,4)
        first_cam_t = first_cam_RT[0:3,3]
        first_cam_c = -np.transpose(first_cam_RT[0:3,0:3]).dot(first_cam_t)
        fpo = np.transpose(first_cam_RT[0:3, 0:3]).dot(np.array([0,0,-1]))
        pp_enu = pp # self.ecef2enu(pp, first_cam_c) #would need to transform the rotations for arrows too, too much effort right now
        #print("pp shape: " + str(pp))
        ax.scatter(pp_enu[:, 0], pp_enu[:, 1], pp_enu[:, 2])
        q_len = np.linalg.norm(np.max(pp_enu, 0) - np.min(pp_enu, 0)) * 0.1 #10% of the extent
        ax.quiver(pp_enu[:, 0], pp_enu[:, 1], pp_enu[:, 2], po[:, 0], po[:, 1], po[:, 2], length = q_len) #arrows for paired views
        ax.quiver(first_cam_c[0], first_cam_c[1], first_cam_c[2], fpo[0], fpo[1], fpo[2], length = q_len, color='red') #arrow for first view
        ax.scatter(first_cam_c[0], first_cam_c[1], first_cam_c[2], c='red')
        plt.title("Camera C, R^T")
        self.writeList(self.pair_names, os.path.join(self.args.output_dir, "pairs_" + image_base + ".txt"))
        plt.savefig(os.path.join(self.args.output_dir, "pairs_" + image_base + ".png"))
        #plt.show()


    def generateAndSavePatches(self, outdir, im_1_fname, im_2_fname, numshared, startimg, startsecondimg):
        print("Generating pair: " + outdir + ", num shared: " + str(numshared) + ", start_image: " +    str(startimg) + ", second: " + str(startsecondimg))
        if not os.path.exists(outdir):
            os.makedirs(outdir)

        try:
            info = getPatches(im_1_fname, im_2_fname, False, 512, 64, 900, measure=False)
            np.save(os.path.join(outdir, "info.npy"), info)
            try:
                dset = os.path.dirname(outdir)
                images_path = os.path.dirname(im_1_fname)
                flist = [os.path.basename(outdir)]
                print(dset, images_path, flist)
                dataset = MultimodalPatchesDataset(dset, images_path, flist,
                                                   numneg=1, pos_thr=1.0, reject=False, dist_type='3D')
                dataloader = DataLoader(dataset, batch_size=300, shuffle=False,
                                        num_workers=0)
                for i_batch, sample_batched in enumerate(dataloader):
                    pass
                    #print(i_batch)

            except Exception as e:
                print("ERROR!", e)
                print("removing: ", outdir)
                shutil.rmtree(outdir)

        except RuntimeError as re:
            print("Unable to get patches for: " + outdir)
            print(re)
            if os.path.isdir(outdir):
                print("removing: ", outdir)
                shutil.rmtree(outdir)


    def generateAndSavePatchesDone(self, arg):
        workers_semaphore.release()


    def testDepthMap(self, depth_name):
        d = loadDepth(depth_name)
        if np.min(d) == np.max(d):
            return False
        return True


    def testAndAdd(self, image_base, dp):
        if (self.isAboveGround(image_base) and self.testDepthMap(dp)):
            return image_base
        return ""


    def createDataset(self):

        pool = get_context("spawn").Pool(processes=self.num_workers)
        async_completions = []

        image_dir = os.path.join(self.args.input_dir, self.args.fov_type)

        restrict_imgs_bare = []
        if (self.args.img_list):
            restrict_imgs_bare = self.readListBasenames(self.args.img_list)
        #find existing images
        restrict_imgs = []
        if (len(restrict_imgs_bare) > 0):
            for image_base in restrict_imgs_bare:
                p = os.path.join(image_dir, image_base + "_texture.png")
                if (os.path.isfile(p)):
                    restrict_imgs.append(image_base)

        if not os.path.exists(self.args.output_dir):
            os.makedirs(self.args.output_dir)

        image_base_list = []
        if len(restrict_imgs) == 0:
            print("Selecting valid images...")
            for image_tex in glob.glob(os.path.join(image_dir, "*_texture.png")):
                image = re.sub("_texture", "", image_tex)
                image_base = os.path.basename(image).split(".")[0]
                dp = os.path.join(image_dir, image_base + "_texture_depth.txt.gz")
                async_res = pool.apply_async(self.testAndAdd, args=(image_base, dp))
                async_completions.append(async_res)

            valid_imgs_fname = os.path.join(self.args.output_dir, "valid_images.txt")
            with open(valid_imgs_fname, 'w') as vf:
                for c in tqdm(async_completions):
                    res = c.get()
                    if len(res) > 0:
                        image_base_list.append(res)
                        vf.write(res + "\n")

            async_completions = []

        self.start_image = 0
        self.start_second_image = 0
        batch_num = 0
        max_count = len(image_base_list)
        if (len(restrict_imgs) > 0):
            max_count = len(restrict_imgs)
        while self.start_image <= max_count - 1:
            self.writeDebugFile("starting new batch, start_image: " + str(self.start_image) + " total images: " + str(len(image_base_list)) + ", second: " + str(self.start_second_image))

            self.resetPairVars()

            domain_parts = self.args.domain.split("-")
            first_image_dom = "_texture" if domain_parts[0] == "synth" else ""
            second_image_dom = "_texture" if domain_parts[1] == "synth" else ""

            #for each image select appropriate pairs based on number of shared points
            batch_finished = False
            img_num = 0
            pair_count = 0
            first_image_base_list = image_base_list
            if (len(restrict_imgs) > 0):
                first_image_base_list = restrict_imgs
            for img_num in range(self.start_image, len(first_image_base_list)):
                image_base = first_image_base_list[img_num]
                im_1_fname = os.path.join(image_dir, image_base + first_image_dom + ".png")

                tracks_file = os.path.join(self.args.input_dir, image_base + "_tracks.txt")
                if (not os.path.isfile(tracks_file)):
                    self.writeDebugFile("Could not find tracks file." + tracks_file)
                    self.start_image = img_num
                    continue

                sorted_keys, tracks = self.parseTracks(tracks_file)

                second_img_num = 0
                for second_img_num in range(self.start_second_image, len(sorted_keys)):
                    self.start_second_image = second_img_num + 1
                    name = sorted_keys[second_img_num]
                    if (tracks[name] > self.args.number_shared):
                        # take the view, it has enough shared 3D points if the image actually exists
                        self.pair_names.append(name + ".png")
                        im_2_fname = os.path.join(image_dir, name + second_image_dom + ".png")
                        if (not os.path.isfile(im_2_fname)):
                            self.writeDebugFile("continuing second because image does not exist: " + im_2_fname)
                            continue
                        if (not self.isAboveGround(name)):
                            self.writeDebugFile("continuing second because not above ground: " + name)
                            continue
                        if (pair_count >= self.args.max_pairs):
                            self.writeDebugFile("Pair count larger than max pairs, pair count: " + str(pair_count) + ", max pairs: " + str(self.args.max_pairs))
                            batch_finished = True
                            batch_num += 1
                            break


                        outdir = os.path.join(self.args.output_dir, image_base + "-" + name)
                        self.writeDebugFile("Generating pair: " + outdir + ", num shared: " + str(tracks[name]) + ", start_image: " + str(self.start_image) + ", second: " + str(self.start_second_image))
                        workers_semaphore.acquire()
                        async_res = pool.apply_async(self.generateAndSavePatches, args=(outdir, im_1_fname, im_2_fname, tracks[name], self.start_image, self.start_second_image), callback=(self.generateAndSavePatchesDone))
                        async_completions.append(async_res)

                        #self.generateAndSavePatches(outdir, im_1_fname, im_2_fname, tracks[name], self.start_image, self.start_second_image)

                        pair_count = pair_count + 1
                    else:
                        # we don't need to continue because sorted_keys are sorted
                        # according to the number of shared 3D views.
                        self.resetPairVars()
                        self.start_second_image = 0
                        self.start_image = img_num + 1
                        break
                if (second_img_num == len(sorted_keys) - 1):
                    self.resetPairVars()
                    self.start_second_image = 0
                    self.start_image = img_num + 1

                self.writeDebugFile("looping finished, start_image: " + str(self.start_image) + ", second: " + str(self.start_second_image) + ", second img num: " + str(second_img_num) + ", len sorted keys: " + str(len(sorted_keys)))
                if (batch_finished):
                    break
        for completion in async_completions:
            completion.wait()
             #res = completion.get()
             #print("res = %d" % res)
        self.writeDebugFile("DONE")


def main():

    ap = buildArgumentParser()
    args = ap.parse_args()

    if (args.domain != "synth-synth" and args.domain != "real-synth" and args.domain != "real-real"):
        print("Error, the domain of dataset must be one of: synth-synth, real-synth, real-real.")
        return
    if (args.fov_type != "fixed" and args.fov_type != "real"):
        print("Error, field-of-view option might be either fixed, or real.")
        return
    dc = PatchesDatasetCreator(args)
    dc.createDataset()


if __name__ == "__main__":
    main()
